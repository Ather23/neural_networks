{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using twitter data\n",
    "\n",
    "Simple Deep Neural Network, that predicts tweet sentiment. The model can be greatly improved using various <br/>\n",
    "word vectorization techniques and Recurrent Neural Networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tflearn as tflearn\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tensorflow import Summary, train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test_path = \"./data/twitter_test.txt\"\n",
    "training_path = \"./data/twitter_data.txt\"\n",
    "\n",
    "def all_stop_words():\n",
    "    stop_words = stopwords.words('english')\n",
    "    add_stopwords = [\",\", \"*\" , \")\" , \"(\" ,\".\",\"theres\",\"know\",\"one\",\"though\",\"vinci\",\"ive\",\"da\",\"book\",\"im\",\"went\",\n",
    "                    \"potter\",\"brokeback\",\"mountain\",\"harry\",\"code\",\"mission\",\"impossible\",\"movie\",\"movies\",\"i\",\"ya\",\n",
    "                    \"yet\",\"yall\"]\n",
    "    for w in add_stopwords:\n",
    "        stop_words.append(w)\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "stop_words = all_stop_words()\n",
    "def training_data_df(path):\n",
    "    \n",
    "    training_data = open(path,mode='r')\n",
    "    training_array =[]\n",
    "    for d in training_data:\n",
    "        training_dict = {}\n",
    "        sent_tweet_array = d.split('\\t')\n",
    "        training_dict['tweet'] = str(sent_tweet_array[1].lower())\n",
    "        training_dict['cleaned_tweet'] =remove_stop_words(sent_tweet_array[1].lower())\n",
    "        training_dict['positive'] =int(sent_tweet_array[0])\n",
    "        training_array.append(training_dict)\n",
    "    training_df = pd.DataFrame(training_array)\n",
    "    return training_df\n",
    "\n",
    "def sentiment(sentiment_prob):\n",
    "    if sentiment_prob[0]>sentiment_prob[1]:\n",
    "        return \"positive\"\n",
    "    return \"negative\"\n",
    "\n",
    "def remove_stop_words(tweet_text):\n",
    "    tweet_text = re.sub(r'[?|$|.|!]',r'',tweet_text)\n",
    "    tweet_text = re.sub(r'[^a-zA-Z0-9 ]',r'',tweet_text)\n",
    "    result = \"\"\n",
    "    for word in tweet_text.split():            \n",
    "        result = result +\" \"+word.lower()\n",
    "\n",
    "    return result.lstrip()\n",
    "\n",
    "def get_word_frequency(tweet_list):\n",
    "    word_dict = {} \n",
    "    result_array=[]\n",
    "    for tw in tweet_list:\n",
    "        for word in tw.split():\n",
    "            if word in word_dict.keys():\n",
    "                word_dict[word] = word_dict[word]+1\n",
    "                continue\n",
    "            word_dict[word] = 1\n",
    "    for k in word_dict.keys():\n",
    "        result_array.append({'word':k, 'count':word_dict[k]})\n",
    "    return pd.DataFrame(result_array,columns=['count','word'])\n",
    "\n",
    "\n",
    "def common_pos_words(df_data):\n",
    "    return common_words_filter(df_data,1)\n",
    "\n",
    "def common_neg_words(df_data):\n",
    "    return common_words_filter(df_data,0)\n",
    "\n",
    "def common_words_filter(df_data,sent):\n",
    "    pos_tweet =df_data[df_data[\"positive\"] ==sent]\n",
    "    all_tweets = pos_tweet[\"tweet\"].str.cat(sep='|')\n",
    "    common_words=[]\n",
    "    for pos_tw in pos_tweet[\"tweet\"]:\n",
    "        for tw in all_tweets.split('|'):\n",
    "            if pos_tw == tw:\n",
    "                continue\n",
    "            tw_list = list(tw.split())\n",
    "            pos_list = list(pos_tw.split())\n",
    "            inter = list(set(tw_list).intersection(pos_list))\n",
    "            for word in inter:\n",
    "                if word not in common_words:\n",
    "                    common_words.append(word)\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data: 7087\n"
     ]
    }
   ],
   "source": [
    "training_data = training_data_df(training_path)\n",
    "# test_data = training_data_df(test_path)\n",
    "training_data[\"neg\"] = training_data[\"positive\"].apply(lambda x: 0 if x==1 else 1)\n",
    "vect = CountVectorizer(stop_words=stop_words)\n",
    "print(\"All data:\",training_data.shape[0])\n",
    "# print(\"Test data:\",test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[\"tweet\"].apply(lambda x:len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: 3995\n",
      "negative: 3092\n"
     ]
    }
   ],
   "source": [
    "print(\"positive:\",len(training_data[training_data[\"positive\"]==1]))\n",
    "print(\"negative:\",len(training_data[training_data[\"positive\"]!=1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2233"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = training_data[['positive','neg','cleaned_tweet', 'tweet']]\n",
    "training_data.values\n",
    "len(training_data[\"cleaned_tweet\"].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neg</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>i feeel like aaa reetard</td>\n",
       "      <td>i feeel like aaa reetard\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the da vinci code book is just awesome</td>\n",
       "      <td>the da vinci code book is just awesome.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>this was the first clive cussler ive ever read...</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i liked the da vinci code a lot</td>\n",
       "      <td>i liked the da vinci code a lot.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i liked the da vinci code a lot</td>\n",
       "      <td>i liked the da vinci code a lot.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i liked the da vinci code but it ultimatly did...</td>\n",
       "      <td>i liked the da vinci code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>thats not even an exaggeration and at midnight...</td>\n",
       "      <td>that's not even an exaggeration ) and at midni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i loved the da vinci code but now i want somet...</td>\n",
       "      <td>i loved the da vinci code, but now i want some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i thought da vinci code was great same with ki...</td>\n",
       "      <td>i thought da vinci code was great, same with k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the da vinci code is actually a good movie</td>\n",
       "      <td>the da vinci code is actually a good movie...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i thought the da vinci code was a pretty good ...</td>\n",
       "      <td>i thought the da vinci code was a pretty good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the da vinci code is one of the most beautiful...</td>\n",
       "      <td>the da vinci code is one of the most beautiful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the da vinci code is an amazing book do not ge...</td>\n",
       "      <td>the da vinci code is an * amazing * book, do n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>then i turn on the light and the radio and enj...</td>\n",
       "      <td>then i turn on the light and the radio and enj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the da vinci code was really good</td>\n",
       "      <td>the da vinci code was really good.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i love da vinci code</td>\n",
       "      <td>i love da vinci code....\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i loved da vinci code</td>\n",
       "      <td>i loved da vinci code..\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>to night the da vinci code and a beautiful mind</td>\n",
       "      <td>to night:: the da vinci code and a beautiful m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the da vinci code is an awesome book</td>\n",
       "      <td>the da vinci code is an awesome book....\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>thing is i enjoyed the da vinci code</td>\n",
       "      <td>thing is, i enjoyed the da vinci code.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    positive  neg                                      cleaned_tweet  \\\n",
       "0          0    1                           i feeel like aaa reetard   \n",
       "1          1    0             the da vinci code book is just awesome   \n",
       "2          1    0  this was the first clive cussler ive ever read...   \n",
       "3          1    0                    i liked the da vinci code a lot   \n",
       "4          1    0                    i liked the da vinci code a lot   \n",
       "5          1    0  i liked the da vinci code but it ultimatly did...   \n",
       "6          1    0  thats not even an exaggeration and at midnight...   \n",
       "7          1    0  i loved the da vinci code but now i want somet...   \n",
       "8          1    0  i thought da vinci code was great same with ki...   \n",
       "9          1    0         the da vinci code is actually a good movie   \n",
       "10         1    0  i thought the da vinci code was a pretty good ...   \n",
       "11         1    0  the da vinci code is one of the most beautiful...   \n",
       "12         1    0  the da vinci code is an amazing book do not ge...   \n",
       "13         1    0  then i turn on the light and the radio and enj...   \n",
       "14         1    0                  the da vinci code was really good   \n",
       "15         1    0                               i love da vinci code   \n",
       "16         1    0                              i loved da vinci code   \n",
       "17         1    0    to night the da vinci code and a beautiful mind   \n",
       "18         1    0               the da vinci code is an awesome book   \n",
       "19         1    0               thing is i enjoyed the da vinci code   \n",
       "\n",
       "                                                tweet  \n",
       "0                          i feeel like aaa reetard\\n  \n",
       "1           the da vinci code book is just awesome.\\n  \n",
       "2   this was the first clive cussler i've ever rea...  \n",
       "3                  i liked the da vinci code a lot.\\n  \n",
       "4                  i liked the da vinci code a lot.\\n  \n",
       "5   i liked the da vinci code but it ultimatly did...  \n",
       "6   that's not even an exaggeration ) and at midni...  \n",
       "7   i loved the da vinci code, but now i want some...  \n",
       "8   i thought da vinci code was great, same with k...  \n",
       "9     the da vinci code is actually a good movie...\\n  \n",
       "10  i thought the da vinci code was a pretty good ...  \n",
       "11  the da vinci code is one of the most beautiful...  \n",
       "12  the da vinci code is an * amazing * book, do n...  \n",
       "13  then i turn on the light and the radio and enj...  \n",
       "14               the da vinci code was really good.\\n  \n",
       "15                         i love da vinci code....\\n  \n",
       "16                          i loved da vinci code..\\n  \n",
       "17  to night:: the da vinci code and a beautiful m...  \n",
       "18         the da vinci code is an awesome book....\\n  \n",
       "19           thing is, i enjoyed the da vinci code.\\n  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_processor = tflearn.data_utils.VocabularyProcessor(45,)\n",
    "# vocab = vocab_processor.fit(training_data[\"tweet\"])\n",
    "vocab = vocab_processor.fit(training_data[\"cleaned_tweet\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open ('mappings.txt','w') as mappings:\n",
    "    words = []\n",
    "    for sent in training_data[\"cleaned_tweet\"]:\n",
    "        mappings.write(\"{}\\n\".format(sent))\n",
    "#         for word in sent.split():            \n",
    "#             if word in words:\n",
    "#                 continue\n",
    "#             index = vocab.vocabulary_.get(word)\n",
    "#             mappings.write(\"{}\\t{}\\n\".format(word, index))\n",
    "#             words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    2    3 ...,    0    0    0]\n",
      " [   6    7    8 ...,    0    0    0]\n",
      " [  14   15    6 ...,    0    0    0]\n",
      " ..., \n",
      " [ 163    1 2230 ...,    0    0    0]\n",
      " [ 411 1179 1180 ...,    0    0    0]\n",
      " [ 188   26 1179 ...,    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "vocab_array =vocab.transform(training_data[\"cleaned_tweet\"],)\n",
    "vocab_array =np.asmatrix(np.array(list(vocab_array)))\n",
    "print(vocab_array)\n",
    "\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = training_data.values[:,:2].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (5315, 45)\n",
      "Test data: (1772, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trX,testX,trY,testY = train_test_split(vocab_array,classes)   \n",
    "# trainY = tflearn.data_utils.to_categorical(trY, nb_classes=2)\n",
    "# testY = tflearn.data_utils.to_categorical(testY, nb_classes=2)\n",
    "\n",
    "print(\"Training data:\",trX.shape)\n",
    "print(\"Test data:\",testX.shape)\n",
    "trY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network\n",
    "\n",
    "\n",
    "Consists of : \n",
    "<ul>\n",
    "<li>Input layer </li> \n",
    "<li>Hidden layer with 300 neurons</li> \n",
    "<li>Output softmax layer, which outputs the likelyhood of a class: [1,0]</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.13537\u001b[0m\u001b[0m | time: 10.376s\n",
      "| Adam | epoch: 005 | loss: 0.13537 - acc: 0.9836 -- iter: 5312/5315\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.12646\u001b[0m\u001b[0m | time: 10.438s\n",
      "| Adam | epoch: 005 | loss: 0.12646 - acc: 0.9821 -- iter: 5315/5315\n",
      "--\n",
      "INFO:tensorflow:/tmp/tflearn_logs/model.ckpt-835 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "sess = tf.Session(graph=graph)\n",
    "input_data = tflearn.input_data(shape=[None,45],name='input_data')\n",
    "\n",
    "embedding = tflearn.embedding(input_data, input_dim=2235, output_dim=45,name='word_embeddings')\n",
    "dropout = tflearn.dropout(embedding,keep_prob=0.10,name='dropout_layer')\n",
    "# lstm_weights = tflearn.initializations.truncated_normal(shape=[45,1])\n",
    "\n",
    "lstm = tflearn.lstm(dropout, 45,name='lstm',activation='relu')\n",
    "softmax_weights = tflearn.initializations.truncated_normal(shape=None,dtype=tf.float32)\n",
    "\n",
    "net = tflearn.fully_connected(lstm, 2, activation='softmax',regularizer='L2',weights_init=softmax_weights,\n",
    "                              name=\"full_layer\")\n",
    "reg = tflearn.regression(net, optimizer='adam', learning_rate=0.001,\n",
    "                     loss='categorical_crossentropy',name='regression',)\n",
    "model = tflearn.DNN(reg,tensorboard_verbose=3,checkpoint_path='/tmp/tflearn_logs/model.ckpt',session=sess)\n",
    "\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "# You can add multiple embeddings. Here we add only one.\n",
    "viz_emd = config.embeddings.add()\n",
    "viz_emd.tensor_name = embedding.name\n",
    "# Link this tensor to its metadata file (e.g. labels).\n",
    "viz_emd.metadata_path = os.path.join(\"/tmp/tflearn_logs\", 'metadata.tsv')\n",
    "# Use the same LOG_DIR where you stored your checkpoint.\n",
    "summary_writer = tf.summary.FileWriter(\"/tmp/tflearn_logs\",graph)\n",
    "# The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will\n",
    "# read this file during startup.\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES,lstm)\n",
    "tf.add_to_collection(tf.GraphKeys.GRAPH_CONFIG,config)\n",
    "tf.add_to_collection(tf.GraphKeys.SUMMARIES,tflearn.summarize_variables([net.W]))\n",
    "\n",
    "\n",
    "tflearn.helpers.summarize(input_data,type='histogram',name='input_sum')\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "sess.run(init_op)\n",
    "\n",
    "model.fit(trX,trY, show_metric=True,batch_size=32,n_epoch=5)\n",
    "# sess.run(print(embedding))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5315, 45, 45)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word_embeddings/embedding_lookup:0'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import os\n",
    "# Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([images])\n",
    "\n",
    "#     sess.run(images.initializer)\n",
    "    saver.save(sess, os.path.join(LOG_DIR, 'images.ckpt'))\n",
    "    config = projector.ProjectorConfig()\n",
    "\n",
    "    # You can add multiple embeddings. Here we add only one.\n",
    "    viz_emd = config.embeddings.add()\n",
    "    viz_emd.tensor_name = \"word_embeddings/W\"\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    viz_emd.metadata_path = os.path.join(\"/tmp/tflearn_logs\", 'metadata.tsv')\n",
    "\n",
    "    # Use the same LOG_DIR where you stored your checkpoint.\n",
    "    summary_writer = tf.summary.FileWriter(\"/tmp/tflearn_logs\")\n",
    "\n",
    "    # The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will\n",
    "    # read this file during startup.\n",
    "    projector.visualize_embeddings(summary_writer, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word_embeddings/W'"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_emd.tensor_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 1, 45) for Tensor 'input_data/X:0', which has shape '(?, 45)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-29aa8ec460ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mauc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-29aa8ec460ee>\u001b[0m in \u001b[0;36mauc_curve\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mp_toarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp_toarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mp_toarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tflearn/helpers/evaluator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feed_dict)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mo_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Reshape pred per sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    945\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 1, 45) for Tensor 'input_data/X:0', which has shape '(?, 45)'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "def auc_curve():\n",
    "    test_y=testY[:,0]\n",
    "    pred = []\n",
    "    i=0\n",
    "    for t in testX:\n",
    "        p = model.predict([t])\n",
    "        p_toarray = np.asarray(p)[0]\n",
    "        if p_toarray[0]>p_toarray[1]:\n",
    "            pred.append(1.0)\n",
    "        else:\n",
    "            pred.append(0.0)\n",
    "    print(metrics.classification_report(test_y.astype(float), np.asarray(pred)))\n",
    "    print(metrics.confusion_matrix(test_y.astype(float), pred))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_y, np.asarray(pred))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('AUC = %0.4f'% roc_auc)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',\n",
    "    label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Sentiment Rate')\n",
    "    plt.xlabel('False Positive Sentiment Rate')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "auc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: the da vinci code book is just awesome.\n",
      "\n",
      "<generator object VocabularyProcessor.transform at 0x115632570>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-0570ae3c5082>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tflearn/helpers/evaluator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feed_dict)\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                         \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   3679\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3680\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3681\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3682\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3683\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enforce_nesting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tflearn/helpers/evaluator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feed_dict)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# Prediction for each tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tflearn/config.py\u001b[0m in \u001b[0;36mis_training\u001b[0;34m(is_training, session)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is_training_ops'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'is_training_ops'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \"\"\"\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3795\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3796\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3797\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "\n",
    "for t in training_data[training_data[\"positive\"] ==1][\"tweet\"].head(10):\n",
    "    print(\"Tweet:\",t)\n",
    "    enc = vocab_processor.fit_transform([t])\n",
    "    print(enc)\n",
    "    p = model.predict(list(enc))\n",
    "    print(np.asarray(p)[0])\n",
    "    print(\"sentiment:\",sentiment(np.asarray(p)[0]))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: i feeel like aaa reetard\n",
      "\n",
      "[ 0.93455815  0.06544185]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: da vinci code was a terrible movie.\n",
      "\n",
      "[ 0.58812284  0.41187713]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: then again, the da vinci code is super shitty movie, and it made like 700 million.\n",
      "\n",
      "[ 0.77344775  0.22655222]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: the da vinci code comes out tomorrow, which sucks.\n",
      "\n",
      "[ 0.77344775  0.22655222]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: i thought the da vinci code movie was really boring.\n",
      "\n",
      "[ 0.93455815  0.06544185]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: god, yahoo games has this truly-awful looking da vinci code-themed skin on it's chessboard right now.\n",
      "\n",
      "[ 0.88189459  0.11810541]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: da vinci code does suck.\n",
      "\n",
      "[ 0.58812284  0.41187713]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: and better...-we all know da vinci code is bogus and inaccurate.\n",
      "\n",
      "[ 0.89590698  0.10409307]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: last time, da vinci code is also a bit disappointing to me, because many things written in the book is never mentioned in movie.\n",
      "\n",
      "[ 0.88561684  0.11438311]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: and better...-we all know da vinci code is bogus and inaccurate.\n",
      "\n",
      "[ 0.89590698  0.10409307]\n",
      "sentiment: positive\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in training_data[training_data[\"positive\"] ==0][\"tweet\"].head(10):\n",
    "    print(\"Tweet:\",t)\n",
    "    enc = vocab_processor.fit_transform(t)\n",
    "    p = model.predict(list(enc))\n",
    "    print(np.asarray(p)[0])\n",
    "    print(\"sentiment:\",sentiment(np.asarray(p)[0]))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Besides the tasty food, the service is incredible!\n",
      "[  9.99985456e-01   1.45690492e-05]\n",
      "sentiment: positive\n",
      "--------\n",
      "Tweet: Horrible service. Absolutely no sense of customer service and how to take an order. Your order will never reach you.\n",
      "[  9.99985456e-01   1.45690492e-05]\n",
      "sentiment: positive\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "testing_file = open(test_path,mode='r')\n",
    "testing_tweets=[]\n",
    "for x in testing_file:\n",
    "    s= remove_stop_words(x)\n",
    "    testing_tweets.append(s)\n",
    "\n",
    "testing_tweets=[\"Besides the tasty food, the service is incredible!\",\n",
    "                \"Horrible service. Absolutely no sense of customer service and how to take an order. Your order will never reach you.\"]\n",
    "\n",
    "# testing_tweets[100:200]    \n",
    "for t in testing_tweets:\n",
    "    print(\"Tweet:\",t)\n",
    "    enc = vocab_processor.fit_transform(t)\n",
    "    p = model.predict(list(enc))\n",
    "    print(np.asarray(p)[0])\n",
    "    print(\"sentiment:\",sentiment(np.asarray(p)[0]))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(vect.transform([\"satisfied\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 64)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.random.random([1024, 64])  # 64-dimensional embeddings\n",
    "ids = np.array([0, 5, 17, 33])\n",
    "matrix.shape\n",
    "#print (matrix[ids] ) # prints a matrix of shape [4, 64] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
